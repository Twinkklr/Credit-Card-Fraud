{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2.0 Modeling\n",
        "\n",
        "The fraud detection approach implemented in this analysis uses a two-stage modeling process. The intent of this design is to apply a broadly applicable decision threshold to the majority of transactions in the first stage, while reserving a more detailed and targeted model for transactions that fall near the decision boundary. This allows the system to maintain high throughput and low customer impact for most transactions, while focusing modeling complexity where it is most valuable.\n",
        "\n",
        "Given the nature of the dataset, fraud is a rare event, with fraudulent transactions representing approximately 0.17% of all observations. This level of class imbalance is a key consideration in both model selection and evaluation. In this context, traditional accuracy metrics are not informative, as a naïve model that predicts all transactions as non-fraudulent would achieve high accuracy while providing no practical value. As a result, Precision–Recall AUC is used as the primary evaluation metric, reflecting both the rarity of fraud and the operational cost associated with false positives.\n",
        "\n",
        "2.1 Stage 1: High-Recall Screening\n",
        "\n",
        "The objective of the first-stage model is to act as a high-recall screening filter, identifying transactions that warrant further examination while allowing the majority of low-risk transactions to pass without additional friction. This stage is intentionally conservative, prioritizing recall over precision to minimize the likelihood of fraudulent transactions being missed early in the process.\n",
        "\n",
        "By design, this stage applies a single threshold across the full dataset and is optimized to capture the vast majority of fraud cases, accepting that some legitimate transactions will be forwarded to the second stage as a result. Transactions not flagged at this stage are treated as low risk and are not evaluated further.\n",
        "\n",
        "2.2 Stage 2: Boundary Refinement\n",
        "\n",
        "Transactions flagged by Stage 1 are passed to a second model focused on refining decisions near the classification boundary. This stage operates on a significantly smaller subset of data and is optimized for precision, with the goal of separating high-confidence fraud from legitimate transactions that were conservatively flagged in the first stage.\n",
        "\n",
        "Multiple operating thresholds were evaluated for the second-stage model in order to understand the tradeoff between fraud capture and customer impact. Based on a review of the resulting confusion matrices, an operating point corresponding to approximately 80% Stage-2 recall was selected for automatic blocking.\n",
        "\n",
        "At this operating point:\n",
        "\n",
        "Approximately 0.002% of legitimate transactions would be incorrectly blocked automatically.\n",
        "\n",
        "An additional 0.019% of transactions would be flagged for customer contact or step-up verification rather than outright blocking.\n",
        "\n",
        "When combined with the first-stage screening, this configuration results in the system identifying approximately 95.3% of fraudulent transactions overall, while keeping false-positive impact on legitimate customers very low. This reflects a deliberate balance between fraud prevention effectiveness and customer experience, rather than an attempt to maximize any single metric in isolation."
      ],
      "metadata": {
        "id": "BfjAZGpdqGRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZXOCWIPpWMb",
        "outputId": "3f93d5b4-088d-49fe-839c-9b9f2a74f8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "\n",
        "# Connect to drive\n",

        "\n",
        "file_path = '/content/drive/MyDrive/Scikit learn/Fraud Classification/creditcard.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, roc_auc_score, precision_recall_curve,\n",
        "    classification_report, confusion_matrix, make_scorer\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
        "from functools import partial\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_predict"
      ],
      "metadata": {
        "id": "qrClpSCrqDQT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Add hour column to show hour of the day a transaction occured.\n",
        "df = pd.read_csv(file_path)\n",
        "df[\"hour\"] = (df[\"Time\"]// 3600)% 24"
      ],
      "metadata": {
        "id": "nI4wXw_Dpn_R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and texting data sets\n",
        "\n",
        "X = df.drop(columns=[\"Class\", \"Time\"])\n",
        "y = df[\"Class\"]  # 1 = fraud, 0 = not fraud\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "0J1eJGGwqAJ0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression models and a HGB classifier, comparing results to determine which models are more effective for data set."
      ],
      "metadata": {
        "id": "TeR2UGFItyuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create pipelines to examine linear regression models with a balanced class weight and no correction for class weight\n",
        "\n",
        "def fit_eval(pipe, X_train, y_train, X_valid, y_valid, name=\"model\"):\n",
        "    pipe.fit(X_train, y_train)\n",
        "    p = pipe.predict_proba(X_valid)[:, 1]\n",
        "    print(f\"\\n{name}\")\n",
        "    print(\"PR AUC:\", average_precision_score(y_valid, p))\n",
        "    print(\"ROC AUC:\", roc_auc_score(y_valid, p))\n",
        "    return p\n",
        "\n",
        "pipe_lr_none = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(max_iter=2000, class_weight=None))\n",
        "])\n",
        "\n",
        "pipe_lr_bal = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "p_none = fit_eval(pipe_lr_none, X_train, y_train, X_valid, y_valid, \"LR (no class_weight)\")\n",
        "p_bal  = fit_eval(pipe_lr_bal,  X_train, y_train, X_valid, y_valid, \"LR (balanced)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZhS_TP2rklg",
        "outputId": "f8a2fa35-f2a7-4691-af8a-8e3a8740b258"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR (no class_weight)\n",
            "PR AUC: 0.7424445995487957\n",
            "ROC AUC: 0.959559615207929\n",
            "\n",
            "LR (balanced)\n",
            "PR AUC: 0.7197876670919009\n",
            "ROC AUC: 0.9717294504323958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HGB model\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(\n",
        "    max_depth = 6,\n",
        "    learning_rate = 0.05,\n",
        "    max_iter = 300,\n",
        "    random_state = 42\n",
        ")\n",
        "\n",
        "hgb.fit(X_train, y_train)\n",
        "p_hgb = hgb.predict_proba(X_valid)[:, 1]\n",
        "\n",
        "print(\"HGB PR AUC:\", average_precision_score(y_valid, p_hgb))\n",
        "print(\"HGB ROC AUC:\", roc_auc_score(y_valid, p_hgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1re8Q4prw69",
        "outputId": "acf6dea2-9ac8-4994-fe36-e875e4843e70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HGB PR AUC: 0.7051514270163073\n",
            "HGB ROC AUC: 0.901171107863517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare 3 models\n",
        "\n",
        "\n",
        "def threshold_for_recall(y_true, p, target_recall= 0.9):\n",
        "  prec, rec, thr = precision_recall_curve(y_true, p)\n",
        "\n",
        "  rec_t = rec[1:]\n",
        "  prec_t = prec[1:]\n",
        "\n",
        "  ok = np.where(rec_t >= target_recall)[0]\n",
        "  if len(ok) ==0:\n",
        "    return 1.0, prec_t[-1], rec_t[-1]\n",
        "\n",
        "  j = ok[-1]\n",
        "  t = thr[j]\n",
        "  return t, prec_t[j], rec_t[j]\n",
        "\n",
        "def eval_at_threshold(y_true, p, t):\n",
        "  y_pred = (p >=t).astype(int)\n",
        "  print(\"Threshold:\", t)\n",
        "  print(confusion_matrix(y_valid, y_pred))\n",
        "  print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "for name, p in {\n",
        "    \"LR (no class_weight)\": p_none,\n",
        "    \"LR (balanced)\": p_bal,\n",
        "    \"HGB\": p_hgb,\n",
        "}.items():\n",
        "  t, pr, rc = threshold_for_recall(y_valid, p, target_recall= 0.90)\n",
        "  print(f\"\\n{name}\")\n",
        "  print(\"threshold:\", t)\n",
        "  print(\"precision:\", pr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-AtpyPvuaMt",
        "outputId": "a062f178-5bda-49eb-84c4-4f25ba3bc480"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR (no class_weight)\n",
            "threshold: 0.001200000791970843\n",
            "precision: 0.019123334765792865\n",
            "\n",
            "LR (balanced)\n",
            "threshold: 0.5557683216815212\n",
            "precision: 0.06732223903177005\n",
            "\n",
            "HGB\n",
            "threshold: 0.0010229736602741576\n",
            "precision: 0.0016354258397282676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that the balanced Linear Regression has the greatest precision.  This model will be tuned with a recall value of 0.95."
      ],
      "metadata": {
        "id": "YQiPMwd3uvPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LR parameter tuning\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Preprocessing: log1p(Amount) + scale (all numeric features)\n",
        "# ------------------------------------------------------------\n",
        "def make_preprocessor(feature_cols, log_amount=True, amount_col=\"Amount\"):\n",
        "    \"\"\"\n",
        "    Builds a ColumnTransformer that:\n",
        "      - imputes missing numeric values with median\n",
        "      - (optionally) log1p-transforms Amount\n",
        "      - scales all numeric features\n",
        "    Assumes all features are numeric (creditcard classic dataset).\n",
        "    \"\"\"\n",
        "    if log_amount and amount_col in feature_cols:\n",
        "        amount_idx = [feature_cols.index(amount_col)]\n",
        "        other_idx = [i for i, c in enumerate(feature_cols) if c != amount_col]\n",
        "\n",
        "        pre = ColumnTransformer(\n",
        "            transformers=[\n",
        "                (\"amount_log\", Pipeline([\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                    (\"log1p\", FunctionTransformer(np.log1p, feature_names_out=\"one-to-one\")),\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                ]), amount_idx),\n",
        "                (\"other_num\", Pipeline([\n",
        "                    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                ]), other_idx),\n",
        "            ],\n",
        "            remainder=\"drop\"\n",
        "        )\n",
        "    else:\n",
        "        pre = Pipeline([\n",
        "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "            (\"scaler\", StandardScaler()),\n",
        "        ])\n",
        "\n",
        "    return pre\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Precision at (at least) a target recall\n",
        "# ------------------------------------------------------------\n",
        "def precision_at_recall(y_true, p, target_recall=0.90):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, p)\n",
        "    prec_t = prec[1:]\n",
        "    rec_t  = rec[1:]\n",
        "\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    j = ok[-1]\n",
        "    val = float(prec_t[j])\n",
        "\n",
        "    # Guard against NaN/inf\n",
        "    if not np.isfinite(val):\n",
        "        return 0.0\n",
        "    return val\n",
        "\n",
        "\n",
        "def _precision_at_recall_scorer_func(y_true, y_score, target_recall):\n",
        "    \"\"\"Internal helper for make_precision_at_recall_scorer.\"\"\"\n",
        "    return precision_at_recall(y_true, y_score, target_recall)\n",
        "\n",
        "def make_precision_at_recall_scorer(target_recall=0.90):\n",
        "    # This will create a picklable scorer\n",
        "    return make_scorer(\n",
        "        _precision_at_recall_scorer_func,\n",
        "        needs_proba=True,\n",
        "        target_recall=target_recall\n",
        "    )\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# FAST LR Optimization (L2 only) with small grid + 3-fold CV\n",
        "# ------------------------------------------------------------\n",
        "def optimize_logistic_regression_fast(\n",
        "    df: pd.DataFrame,\n",
        "    target_col: str = \"Class\",\n",
        "    drop_cols: list | None = None,\n",
        "    log_amount: bool = True,\n",
        "    target_recall_for_report: float = 0.90,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    if drop_cols is None:\n",
        "        drop_cols = []\n",
        "\n",
        "    X = df.drop(columns=[target_col] + drop_cols).copy()\n",
        "    y = df[target_col].astype(int).copy()\n",
        "\n",
        "    feature_cols = list(X.columns)\n",
        "    pre = make_preprocessor(feature_cols, log_amount=log_amount, amount_col=\"Amount\")\n",
        "\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"preprocess\", pre),\n",
        "        (\"model\", LogisticRegression(\n",
        "            solver=\"lbfgs\",\n",
        "            penalty=\"l2\",\n",
        "            max_iter=2000,\n",
        "            random_state=random_state\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Small grid = fast\n",
        "    param_grid = [{\n",
        "        \"model__C\": [0.05, 0.1, 0.5, 1.0],\n",
        "        \"model__class_weight\": [None, \"balanced\"],\n",
        "    }]\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
        "\n",
        "    scorers = {\n",
        "        \"pr_auc\": \"average_precision\",\n",
        "        \"roc_auc\": \"roc_auc\",\n",
        "        f\"precision_at_recall_{target_recall_for_report:.2f}\": make_precision_at_recall_scorer(target_recall_for_report),\n",
        "    }\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        estimator=pipe,\n",
        "        param_grid=param_grid,\n",
        "        scoring=scorers,\n",
        "        refit=\"pr_auc\",\n",
        "        cv=cv,\n",
        "        n_jobs=2,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    gs.fit(X, y)\n",
        "    return gs\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Evaluate best estimator at a target recall using OOF predictions\n",
        "# ------------------------------------------------------------\n",
        "def evaluate_at_target_recall(best_estimator, X, y, target_recall=0.90, cv_splits=3, random_state=42):\n",
        "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Out-of-fold predicted probabilities for an unbiased threshold choice\n",
        "    p_oof = cross_val_predict(\n",
        "        best_estimator, X, y,\n",
        "        cv=cv, method=\"predict_proba\", n_jobs=2\n",
        "    )[:, 1]\n",
        "\n",
        "    print(f\"OOF PR AUC: {average_precision_score(y, p_oof):.6f}\")\n",
        "    print(f\"OOF ROC AUC: {roc_auc_score(y, p_oof):.6f}\")\n",
        "\n",
        "    prec, rec, thr = precision_recall_curve(y, p_oof)\n",
        "    prec_t, rec_t = prec[1:], rec[1:]\n",
        "\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        print(f\"Could not reach recall >= {target_recall:.2f} with this model.\")\n",
        "        return\n",
        "\n",
        "    j = ok[-1]  # highest threshold meeting recall\n",
        "    t = thr[j]\n",
        "\n",
        "    y_pred = (p_oof >= t).astype(int)\n",
        "\n",
        "    print(f\"Chosen threshold for recall≥{target_recall:.2f}: {t:.6g}\")\n",
        "    print(f\"Precision at that point: {prec_t[j]:.6f}\")\n",
        "    print(f\"Recall at that point: {rec_t[j]:.6f}\")\n",
        "    print(confusion_matrix(y, y_pred))\n",
        "    print(classification_report(y, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "gs = optimize_logistic_regression_fast(\n",
        "    df=df,\n",
        "    target_col=\"Class\",\n",
        "    drop_cols=[\"Time\"],          # drop if present; remove if you already dropped it\n",
        "    log_amount=True,\n",
        "    target_recall_for_report=0.95,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Best params (by PR AUC):\", gs.best_params_)\n",
        "print(\"Best CV PR AUC:\", gs.best_score_)\n",
        "\n",
        "# Evaluate operating point with out-of-fold predictions\n",
        "X_all = df.drop(columns=[\"Class\", \"Time\"]) if \"Time\" in df.columns else df.drop(columns=[\"Class\"])\n",
        "y_all = df[\"Class\"].astype(int)\n",
        "\n",
        "evaluate_at_target_recall(gs.best_estimator_, X_all, y_all, target_recall=0.95, cv_splits=3, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRc-2dx5ugXM",
        "outputId": "c636e0fe-a7a7-446b-c446-60724159d195"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (by PR AUC): {'model__C': 0.5, 'model__class_weight': None}\n",
            "Best CV PR AUC: 0.756405814595492\n",
            "OOF PR AUC: 0.755582\n",
            "OOF ROC AUC: 0.977520\n",
            "Chosen threshold for recall≥0.95: 0.000626186\n",
            "Precision at that point: 0.011053\n",
            "Recall at that point: 0.951220\n",
            "[[242442  41873]\n",
            " [    24    468]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9999    0.8527    0.9205    284315\n",
            "           1     0.0111    0.9512    0.0219       492\n",
            "\n",
            "    accuracy                         0.8529    284807\n",
            "   macro avg     0.5055    0.9020    0.4712    284807\n",
            "weighted avg     0.9982    0.8529    0.9189    284807\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameters\n",
        "\n",
        "stage1 = gs.best_estimator_\n",
        "\n",
        "X_all = df.drop(columns=[\"Class\", \"Time\"])\n",
        "y_all = df[\"Class\"].astype(int)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "p_oof = cross_val_predict(\n",
        "    stage1, X_all, y_all,\n",
        "    cv=cv, method=\"predict_proba\", n_jobs=2\n",
        ")[:, 1]\n",
        "\n",
        "prec, rec, thr = precision_recall_curve(y_all, p_oof)\n",
        "prec_t, rec_t = prec[1:], rec[1:]   # align with thr\n",
        "\n",
        "target_recall = 0.95\n",
        "ok = np.where(rec_t >= target_recall)[0]\n",
        "j = ok[-1]                          # highest threshold meeting recall\n",
        "t_gate = thr[j]\n",
        "\n",
        "print(\"Stage-1 gate threshold (recall≥0.95):\", t_gate)\n",
        "print(\"OOF precision at gate:\", prec_t[j])\n",
        "print(\"OOF recall at gate:\", rec_t[j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71riyqav8N3",
        "outputId": "4e8fca81-5efa-43df-ff6b-e3f852892bc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage-1 gate threshold (recall≥0.95): 0.0006261859674817748\n",
            "OOF precision at gate: 0.011053377420878602\n",
            "OOF recall at gate: 0.9512195121951219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove transactions that were not classified as fraud at 95% recall threshold\n",
        "\n",
        "flag = (p_oof >= t_gate)   # use OOF flagging to build stage-2 training data\n",
        "\n",
        "X_stage2 = X_all.loc[flag].copy()\n",
        "y_stage2 = y_all.loc[flag].copy()\n",
        "\n",
        "stage2_df = X_stage2.copy()\n",
        "stage2_df[\"Class\"] = y_stage2.values\n",
        "\n",
        "print(\"Stage-2 rows:\", X_stage2.shape[0])\n",
        "print(\"Stage-2 fraud rate:\", y_stage2.mean())\n",
        "print(\"Percent routed to Stage-2:\", flag.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcVJToNHxHMI",
        "outputId": "72eb9124-33c1-46e6-df62-c312940fa8b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage-2 rows: 42341\n",
            "Stage-2 fraud rate: 0.01105311636475284\n",
            "Percent routed to Stage-2: 0.14866558757333914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Evaluate linear regression, random forest, and HGB models to determine best model type for stage-2 training set\n",
        "\n",
        "def precision_at_recall(y_true, p, target_recall=0.80):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, p)\n",
        "    prec_t, rec_t = prec[1:], rec[1:]\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        return 0.0\n",
        "    return float(prec_t[ok[-1]])\n",
        "\n",
        "\n",
        "def eval_model_cv(model, X, y, cv, target_recall=0.80):\n",
        "    p = cross_val_predict(model, X, y, cv=cv, method=\"predict_proba\", n_jobs=2)[:, 1]\n",
        "    return {\n",
        "        \"PR_AUC\": average_precision_score(y, p),\n",
        "        \"ROC_AUC\": roc_auc_score(y, p),\n",
        "        f\"Prec@Rec{target_recall:.2f}\": precision_at_recall(y, p, target_recall=target_recall),\n",
        "        \"Stage2_FraudRate\": float(y.mean()),\n",
        "        \"Pred_Prob_Mean\": float(np.mean(p)),\n",
        "    }\n",
        "\n",
        "\n",
        "cv2 = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"LR_l2\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=2000))\n",
        "    ]),\n",
        "    \"LR_balanced_l2\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
        "    ]),\n",
        "    \"HGB\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"clf\", HistGradientBoostingClassifier(max_depth=3, learning_rate=0.1, random_state=42))\n",
        "    ]),\n",
        "    \"RF\": Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"clf\", RandomForestClassifier(\n",
        "            n_estimators=300,\n",
        "            random_state=42,\n",
        "            n_jobs=2,\n",
        "            class_weight=None\n",
        "        ))\n",
        "    ]),\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    metrics = eval_model_cv(model, X_stage2, y_stage2, cv=cv2, target_recall=0.80)\n",
        "    metrics[\"Model\"] = name\n",
        "    results.append(metrics)\n",
        "\n",
        "res_df = pd.DataFrame(results).sort_values(\"PR_AUC\", ascending=False)\n",
        "res_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "1qVMh-7l4kta",
        "outputId": "cc98a5ec-8282-481d-d71e-e80503e980f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PR_AUC   ROC_AUC  Prec@Rec0.80  Stage2_FraudRate  Pred_Prob_Mean  \\\n",
              "3  0.885800  0.970732      0.951777          0.011053        0.011197   \n",
              "2  0.870918  0.974860      0.930521          0.011053        0.010748   \n",
              "0  0.796134  0.959786      0.801282          0.011053        0.011103   \n",
              "1  0.777568  0.966507      0.822368          0.011053        0.093121   \n",
              "\n",
              "            Model  \n",
              "3              RF  \n",
              "2             HGB  \n",
              "0           LR_l2  \n",
              "1  LR_balanced_l2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70770c21-bead-45a9-9521-25d87acb53d5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PR_AUC</th>\n",
              "      <th>ROC_AUC</th>\n",
              "      <th>Prec@Rec0.80</th>\n",
              "      <th>Stage2_FraudRate</th>\n",
              "      <th>Pred_Prob_Mean</th>\n",
              "      <th>Model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.885800</td>\n",
              "      <td>0.970732</td>\n",
              "      <td>0.951777</td>\n",
              "      <td>0.011053</td>\n",
              "      <td>0.011197</td>\n",
              "      <td>RF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.870918</td>\n",
              "      <td>0.974860</td>\n",
              "      <td>0.930521</td>\n",
              "      <td>0.011053</td>\n",
              "      <td>0.010748</td>\n",
              "      <td>HGB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.796134</td>\n",
              "      <td>0.959786</td>\n",
              "      <td>0.801282</td>\n",
              "      <td>0.011053</td>\n",
              "      <td>0.011103</td>\n",
              "      <td>LR_l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.777568</td>\n",
              "      <td>0.966507</td>\n",
              "      <td>0.822368</td>\n",
              "      <td>0.011053</td>\n",
              "      <td>0.093121</td>\n",
              "      <td>LR_balanced_l2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70770c21-bead-45a9-9521-25d87acb53d5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70770c21-bead-45a9-9521-25d87acb53d5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70770c21-bead-45a9-9521-25d87acb53d5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eccc3431-4503-47af-ac6e-12def800598c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eccc3431-4503-47af-ac6e-12def800598c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eccc3431-4503-47af-ac6e-12def800598c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_9734a9b2-5da1-42cc-ada3-3b64b69105c7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('res_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9734a9b2-5da1-42cc-ada3-3b64b69105c7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('res_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "res_df",
              "summary": "{\n  \"name\": \"res_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"PR_AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05371767738812243,\n        \"min\": 0.7775679614530123,\n        \"max\": 0.8858002700967968,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8709175940587689,\n          0.7775679614530123,\n          0.8858002700967968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC_AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006434502030934378,\n        \"min\": 0.9597863176422152,\n        \"max\": 0.9748597254090055,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9748597254090055,\n          0.9665066794362522,\n          0.9707315527354694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prec@Rec0.80\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07565892618792396,\n        \"min\": 0.8012820512820513,\n        \"max\": 0.9517766497461929,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9305210918114144,\n          0.8223684210526315,\n          0.9517766497461929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stage2_FraudRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.01105311636475284,\n        \"max\": 0.01105311636475284,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01105311636475284\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_Prob_Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.041053168296122135,\n        \"min\": 0.010747817067968348,\n        \"max\": 0.09312142574674355,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.010747817067968348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"HGB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning HGB model as it performed only slightly worse than RF in initial comparison, as it will more effectivly allow thresholds.  Using a threshold of 0.8 for recall overall for immediate transaction cancellation, and higher thresholds for investigation to be flagged."
      ],
      "metadata": {
        "id": "5loy5ZlP5lEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "# Precision at target recall\n",
        "# -----------------------------\n",
        "def precision_at_recall(y_true, p, target_recall=0.80):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, p)\n",
        "    prec_t, rec_t = prec[1:], rec[1:]  # align with thr\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        return 0.0\n",
        "    val = float(prec_t[ok[-1]])\n",
        "    return 0.0 if not np.isfinite(val) else val\n",
        "\n",
        "# Helper function for make_scorer that receives y_true and y_score (probabilities)\n",
        "def _precision_at_recall_scorer_func_stage2(y_true, y_score, target_recall):\n",
        "    return precision_at_recall(y_true, y_score, target_recall)\n",
        "\n",
        "def make_precision_at_recall_scorer_stage2(target_recall=0.80):\n",
        "    return make_scorer(\n",
        "        _precision_at_recall_scorer_func_stage2,\n",
        "        needs_proba=True,\n",
        "        target_recall=target_recall\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# OOF evaluation helper\n",
        "# -----------------------------\n",
        "def oof_eval(estimator, X, y, cv, target_recall=0.80, n_jobs=2):\n",
        "    p_oof = cross_val_predict(estimator, X, y, cv=cv, method=\"predict_proba\", n_jobs=n_jobs)[:, 1]\n",
        "\n",
        "    pr_auc = average_precision_score(y, p_oof)\n",
        "    roc_auc = roc_auc_score(y, p_oof)\n",
        "\n",
        "    prec, rec, thr = precision_recall_curve(y, p_oof)\n",
        "    prec_t, rec_t = prec[1:], rec[1:]\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    j = ok[-1] if len(ok) else None\n",
        "\n",
        "    thr_star = float(thr[j]) if j is not None else np.nan\n",
        "    prec_star = float(prec_t[j]) if j is not None else 0.0\n",
        "    rec_star = float(rec_t[j]) if j is not None else 0.0\n",
        "\n",
        "    y_pred = (p_oof >= thr_star).astype(int) if np.isfinite(thr_star) else np.zeros_like(y, dtype=int)\n",
        "\n",
        "    return {\n",
        "        \"OOF_PR_AUC\": pr_auc,\n",
        "        \"OOF_ROC_AUC\": roc_auc,\n",
        "        f\"OOF_Prec@Rec{target_recall:.2f}\": prec_star,\n",
        "        f\"OOF_Thr@Rec{target_recall:.2f}\": thr_star,\n",
        "        f\"OOF_Rec@Thr\": rec_star,\n",
        "        \"confusion_matrix\": confusion_matrix(y, y_pred),\n",
        "        \"classification_report\": classification_report(y, y_pred, digits=4, zero_division=0),\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# FAST HGB tuning (Colab-slow friendly)\n",
        "# -----------------------------\n",
        "def tune_hgb_stage2(\n",
        "    X_stage2,\n",
        "    y_stage2,\n",
        "    target_recall=0.80,\n",
        "    random_state=42\n",
        "):\n",
        "    cv2 = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"clf\", HistGradientBoostingClassifier(\n",
        "            random_state=random_state\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Small grid: informative but fast\n",
        "    param_grid = {\n",
        "        \"clf__learning_rate\": [0.05, 0.1],\n",
        "        \"clf__max_depth\": [3, 4],\n",
        "        \"clf__max_iter\": [200, 400],\n",
        "        \"clf__min_samples_leaf\": [50, 100],\n",
        "        \"clf__l2_regularization\": [0.0, 1.0],\n",
        "    }\n",
        "\n",
        "    scorers = {\n",
        "        \"pr_auc\": \"average_precision\",\n",
        "        \"roc_auc\": \"roc_auc\",\n",
        "        f\"prec_at_rec_{target_recall:.2f}\": make_precision_at_recall_scorer_stage2(target_recall), # Changed function name\n",
        "    }\n",
        "\n",
        "    # Suppress the specific UserWarning about non-finite scores from GridSearchCV\n",
        "    warnings.filterwarnings(\n",
        "        'ignore',\n",
        "        message='One or more of the test scores are non-finite:.*',\n",
        "        category=UserWarning,\n",
        "        module='sklearn.model_selection._search'\n",
        "    )\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        pipe,\n",
        "        param_grid,\n",
        "        scoring=scorers,\n",
        "        refit=f\"prec_at_rec_{target_recall:.2f}\",   # choose best for your operating goal\n",
        "        cv=cv2,\n",
        "        n_jobs=2,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    gs.fit(X_stage2, y_stage2)\n",
        "\n",
        "    # Reset warnings to default behavior after GridSearchCV\n",
        "    warnings.filterwarnings('default')\n",
        "\n",
        "    return gs, cv2\n",
        "\n",
        "# -----------------------------\n",
        "# RUN (Stage 2)\n",
        "# -----------------------------\n",
        "# Assumes you already built these:\n",
        "# X_stage2, y_stage2\n",
        "\n",
        "target_recall_stage2 = 0.80\n",
        "\n",
        "hgb_gs, cv2 = tune_hgb_stage2(\n",
        "    X_stage2=X_stage2,\n",
        "    y_stage2=y_stage2,\n",
        "    target_recall=target_recall_stage2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Best params (Stage-2 HGB):\", hgb_gs.best_params_)\n",
        "print(\"Best CV Prec@Rec:\", hgb_gs.best_score_)\n",
        "\n",
        "# OOF evaluation of tuned winner\n",
        "hgb_best = hgb_gs.best_estimator_\n",
        "metrics = oof_eval(hgb_best, X_stage2, y_stage2, cv=cv2, target_recall=target_recall_stage2, n_jobs=2)\n",
        "\n",
        "print(\"OOF PR AUC:\", metrics[\"OOF_PR_AUC\"])\n",
        "print(\"OOF ROC AUC:\", metrics[\"OOF_ROC_AUC\"])\n",
        "print(f\"OOF Prec@Rec{target_recall_stage2:.2f}:\", metrics[f\"OOF_Prec@Rec{target_recall_stage2:.2f}\"])\n",
        "print(f\"OOF Thr@Rec{target_recall_stage2:.2f}:\", metrics[f\"OOF_Thr@Rec{target_recall_stage2:.2f}\"])\n",
        "print(metrics[\"confusion_matrix\"])\n",
        "print(metrics[\"classification_report\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdEaI7Uq5SOp",
        "outputId": "65859bb6-389e-4854-896e-aef68c5b4aad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
            "Best params (Stage-2 HGB): {'clf__l2_regularization': 0.0, 'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__max_iter': 200, 'clf__min_samples_leaf': 50}\n",
            "Best CV Prec@Rec: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF PR AUC: 0.8949282010943328\n",
            "OOF ROC AUC: 0.9779109490827066\n",
            "OOF Prec@Rec0.80: 0.9566326530612245\n",
            "OOF Thr@Rec0.80: 0.698406579799198\n",
            "[[41855    18]\n",
            " [   93   375]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9978    0.9996    0.9987     41873\n",
            "           1     0.9542    0.8013    0.8711       468\n",
            "\n",
            "    accuracy                         0.9974     42341\n",
            "   macro avg     0.9760    0.9004    0.9349     42341\n",
            "weighted avg     0.9973    0.9974    0.9973     42341\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine threshold and confusion matrix for different recall levels\n",
        "\n",
        "def eval_stage2_at_recall(y_true, p, target_recall):\n",
        "    prec, rec, thr = precision_recall_curve(y_true, p)\n",
        "    prec_t, rec_t = prec[1:], rec[1:]  # align with thr\n",
        "\n",
        "    ok = np.where(rec_t >= target_recall)[0]\n",
        "    if len(ok) == 0:\n",
        "        print(f\"Cannot reach recall ≥ {target_recall:.2f}\")\n",
        "        return\n",
        "\n",
        "    j = ok[-1]\n",
        "    t = thr[j]\n",
        "\n",
        "    y_pred = (p >= t).astype(int)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(f\"\\nTarget recall ≥ {target_recall:.2f}\")\n",
        "    print(f\"Threshold: {t:.6g}\")\n",
        "    print(f\"Precision: {prec_t[j]:.4f} | Recall: {rec_t[j]:.4f}\")\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "    print(classification_report(y_true, y_pred, digits=4, zero_division=0))\n",
        "\n",
        "# Get Stage-2 probabilities (OOF-style is best; if you already have p_oof, use it)\n",
        "# If you don't, here's a simple way using your tuned estimator on Stage-2 set:\n",
        "p_stage2 = hgb_best.predict_proba(X_stage2)[:, 1]\n",
        "\n",
        "for r in [0.80, 0.90, 0.95, 0.99]:\n",
        "    eval_stage2_at_recall(y_stage2, p_stage2, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PByOrLH6d3R",
        "outputId": "81f1137b-1e25-4e13-ed83-201ffabde7c4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target recall ≥ 0.80\n",
            "Threshold: 0.871056\n",
            "Precision: 0.9894 | Recall: 0.8013\n",
            "Confusion matrix:\n",
            " [[41868     5]\n",
            " [   93   375]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9978    0.9999    0.9988     41873\n",
            "           1     0.9868    0.8013    0.8844       468\n",
            "\n",
            "    accuracy                         0.9977     42341\n",
            "   macro avg     0.9923    0.9006    0.9416     42341\n",
            "weighted avg     0.9977    0.9977    0.9976     42341\n",
            "\n",
            "\n",
            "Target recall ≥ 0.90\n",
            "Threshold: 0.377944\n",
            "Precision: 0.9420 | Recall: 0.9017\n",
            "Confusion matrix:\n",
            " [[41847    26]\n",
            " [   45   423]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9989    0.9994    0.9992     41873\n",
            "           1     0.9421    0.9038    0.9226       468\n",
            "\n",
            "    accuracy                         0.9983     42341\n",
            "   macro avg     0.9705    0.9516    0.9609     42341\n",
            "weighted avg     0.9983    0.9983    0.9983     42341\n",
            "\n",
            "\n",
            "Target recall ≥ 0.95\n",
            "Threshold: 0.161162\n",
            "Precision: 0.8918 | Recall: 0.9509\n",
            "Confusion matrix:\n",
            " [[41818    55]\n",
            " [   23   445]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9995    0.9987    0.9991     41873\n",
            "           1     0.8900    0.9509    0.9194       468\n",
            "\n",
            "    accuracy                         0.9982     42341\n",
            "   macro avg     0.9447    0.9748    0.9592     42341\n",
            "weighted avg     0.9982    0.9982    0.9982     42341\n",
            "\n",
            "\n",
            "Target recall ≥ 0.99\n",
            "Threshold: 0.0471522\n",
            "Precision: 0.7424 | Recall: 0.9915\n",
            "Confusion matrix:\n",
            " [[41711   162]\n",
            " [    4   464]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9999    0.9961    0.9980     41873\n",
            "           1     0.7412    0.9915    0.8483       468\n",
            "\n",
            "    accuracy                         0.9961     42341\n",
            "   macro avg     0.8706    0.9938    0.9231     42341\n",
            "weighted avg     0.9970    0.9961    0.9964     42341\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fallout of false positives at 80% recall\n",
        "\n",
        "percent_80 = 5/284315*100\n",
        "\n",
        "percent_95 = 55/284315*100\n",
        "\n",
        "percent_95_fallout = 23/492*100\n",
        "\n",
        "print(\"The false positives blocking transactons for the 0.8 threshold is:\", round(percent_80, 3), \"%\")\n",
        "\n",
        "print(\"The flagged/contact customer rate for standard transactions for the 0.95 threshold is:\", round(percent_95, 3), \"%\")\n",
        "\n",
        "print(\"The fraudulent claims that would be missed after blocking and flagging are:\", round(percent_95_fallout, 3), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Moj0fyj-1W0",
        "outputId": "50bc04ed-8d78-4d2f-d1bb-46a127112559"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The false positives blocking transactons for the 0.8 threshold is: 0.002 %\n",
            "The flagged/contact customer rate for standard transactions for the 0.95 threshold is: 0.019 %\n",
            "The fraudulent claims that would be missed after blocking and flagging are: 4.675 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After reviewing the confusion matrices at each operating threshold, setting the automatic block threshold at the 80% Stage-2 recall point would result in approximately 0.002% of legitimate transactions being incorrectly blocked. An additional 0.019% of transactions would be flagged for customer contact or step-up verification. With this configuration, the two-stage system identifies approximately 95.3% of fraudulent transactions overall, while keeping customer impact from false positives very low."
      ],
      "metadata": {
        "id": "bXwMSOLP9Yw7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eX-PO97G86AR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
